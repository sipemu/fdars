---
title: "Finding the Best Basis Representation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Finding the Best Basis Representation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5
)
```

## Introduction

Basis representation is fundamental in functional data analysis. Instead of working
with raw observations at discrete points, we represent curves as linear combinations
of basis functions:

$$X(t) = \sum_{k=1}^{K} c_k B_k(t)$$

where $B_k(t)$ are basis functions and $c_k$ are coefficients.

This approach provides:

- **Smoothing**: Reduces noise by projecting onto a lower-dimensional space
- **Dimensionality reduction**: Represents infinite-dimensional functions with finite coefficients
- **Regularization**: Controls curve smoothness through basis choice and penalties

**fdars** provides tools to find the optimal basis representation for your data.

```{r setup}
library(fdars)
library(ggplot2)
set.seed(42)
```

## Creating Example Data

Let's create functional data with a known signal plus noise:

```{r example-data}
# Generate noisy functional data
t <- seq(0, 1, length.out = 100)
n <- 30  # number of curves

# True underlying signal: mixture of sin waves
true_signal <- function(t) sin(2 * pi * t) + 0.5 * sin(4 * pi * t)

# Generate noisy observations
X <- matrix(0, n, length(t))
for (i in 1:n) {
  X[i, ] <- true_signal(t) + rnorm(length(t), sd = 0.3)
}
fd <- fdata(X, argvals = t)

# Plot the data
plot(fd, alpha = 0.3)
```

## Choosing a Basis Type

**fdars** supports two main basis types:

### B-splines (default)

- Best for **non-periodic** data
- Local support: each basis function is non-zero only in a limited region
- Good for capturing local features
- Computationally efficient

### Fourier Basis

- Best for **periodic** data (cycles, seasonal patterns)
- Global support: each basis function spans the entire domain
- Natural for data with harmonic structure

```{r basis-comparison}
# Compare B-spline and Fourier representations
coefs_bspline <- fdata2basis(fd, nbasis = 15, type = "bspline")
coefs_fourier <- fdata2basis(fd, nbasis = 15, type = "fourier")

# Reconstruct
fd_bspline <- basis2fdata(coefs_bspline, argvals = t, type = "bspline")
fd_fourier <- basis2fdata(coefs_fourier, argvals = t, type = "fourier")

# Plot comparison for first curve
df_compare <- data.frame(
  t = rep(t, 3),
  value = c(fd$data[1, ], fd_bspline$data[1, ], fd_fourier$data[1, ]),
  type = factor(rep(c("Original", "B-spline (K=15)", "Fourier (K=15)"), each = length(t)),
                levels = c("Original", "B-spline (K=15)", "Fourier (K=15)"))
)

ggplot(df_compare, aes(x = t, y = value, color = type, linewidth = type)) +
  geom_line() +
  scale_color_manual(values = c("Original" = "gray50", "B-spline (K=15)" = "blue",
                                 "Fourier (K=15)" = "red")) +
  scale_linewidth_manual(values = c("Original" = 0.5, "B-spline (K=15)" = 1,
                                     "Fourier (K=15)" = 1)) +
  facet_wrap(~ type, ncol = 2, scales = "fixed") +
  labs(x = "t", y = "X(t)", title = "Basis Representation Comparison") +
  theme_minimal() +
  theme(legend.position = "none")
```

For our sinusoidal data, Fourier basis is more natural since the true signal is
composed of sine waves.

## Selecting the Number of Basis Functions

The key question: **How many basis functions should we use?**

- Too few: Underfitting (misses important features)
- Too many: Overfitting (fits noise)

### Information Criteria

**fdars** provides three criteria to evaluate basis representations:

| Criterion | Formula | Penalizes |
|-----------|---------|-----------|
| GCV | $\frac{RSS/n}{(1 - edf/n)^2}$ | Effective degrees of freedom |
| AIC | $n \log(RSS/n) + 2 \cdot edf$ | Model complexity (moderate) |
| BIC | $n \log(RSS/n) + \log(n) \cdot edf$ | Model complexity (strong) |

```{r information-criteria}
# Compute criteria for different nbasis values
nbasis_range <- 5:25

gcv_scores <- sapply(nbasis_range, function(k) basis.gcv(fd, nbasis = k, type = "fourier"))
aic_scores <- sapply(nbasis_range, function(k) basis.aic(fd, nbasis = k, type = "fourier"))
bic_scores <- sapply(nbasis_range, function(k) basis.bic(fd, nbasis = k, type = "fourier"))

# Find optimal values
opt_gcv <- nbasis_range[which.min(gcv_scores)]
opt_aic <- nbasis_range[which.min(aic_scores)]
opt_bic <- nbasis_range[which.min(bic_scores)]

# Create data frame for plotting
df_criteria <- data.frame(
  nbasis = rep(nbasis_range, 3),
  score = c(gcv_scores, aic_scores, bic_scores),
  criterion = rep(c("GCV", "AIC", "BIC"), each = length(nbasis_range)),
  optimal = c(nbasis_range == opt_gcv, nbasis_range == opt_aic, nbasis_range == opt_bic)
)

df_optimal <- data.frame(
  criterion = c("GCV", "AIC", "BIC"),
  nbasis = c(opt_gcv, opt_aic, opt_bic)
)

ggplot(df_criteria, aes(x = nbasis, y = score)) +
  geom_line(color = "steelblue") +
  geom_point(color = "steelblue") +
  geom_vline(data = df_optimal, aes(xintercept = nbasis),
             linetype = "dashed", color = "red") +
  facet_wrap(~ criterion, scales = "free_y") +
  labs(x = "Number of basis functions", y = "Score",
       title = "Information Criteria for Basis Selection") +
  theme_minimal()

cat("Optimal nbasis - GCV:", opt_gcv, "\n")
cat("Optimal nbasis - AIC:", opt_aic, "\n")
cat("Optimal nbasis - BIC:", opt_bic, "\n")
```

**Interpretation:**

- **GCV** (Generalized Cross-Validation): Often a good default, balances fit and complexity
- **AIC**: Tends to select slightly more complex models
- **BIC**: More conservative, penalizes complexity more strongly for larger samples

### Automatic Selection with `fdata2basis.cv()`

For convenience, use `fdata2basis.cv()` to automatically find the optimal number
of basis functions:

```{r automatic-selection}
# Automatic selection using GCV
cv_result <- fdata2basis.cv(fd, nbasis.range = 5:25, type = "fourier", criterion = "GCV")
print(cv_result)

# Visualize the selection
plot(cv_result)
```

The function returns the optimal number of basis functions and the fitted curves:

```{r cv-result}
# Plot the smoothed data
plot(cv_result$fitted, alpha = 0.5, main = paste("Smoothed with", cv_result$optimal.nbasis, "Fourier basis"))
```

### K-fold Cross-Validation

For a more robust estimate, use k-fold cross-validation:
```{r kfold-cv, eval=FALSE}
# K-fold cross-validation (slower but more robust)
cv_kfold <- fdata2basis.cv(fd, nbasis.range = 5:25, type = "fourier",
                            criterion = "CV", kfold = 10)
print(cv_kfold$optimal.nbasis)
```

## P-spline Smoothing

P-splines (Penalized B-splines) offer an alternative approach: instead of selecting
the number of basis functions, we use many basis functions but add a roughness penalty:

$$\text{minimize} \quad ||y - Bc||^2 + \lambda c' D' D c$$

where:
- $B$ is the B-spline basis matrix
- $c$ are coefficients
- $D$ is a difference matrix (controls smoothness)
- $\lambda$ is the penalty parameter

```{r pspline-intro}
# Fit P-spline with fixed lambda
result_fixed <- pspline(fd[1], nbasis = 25, lambda = 10)
print(result_fixed)

# Compare different lambda values
lambdas <- c(0.01, 1, 100, 10000)
df_lambda <- do.call(rbind, lapply(lambdas, function(lam) {
  result <- pspline(fd[1], nbasis = 25, lambda = lam)
  data.frame(
    t = rep(t, 2),
    value = c(fd$data[1, ], result$fdata$data[1, ]),
    type = rep(c("Original", "Smoothed"), each = length(t)),
    lambda = paste("lambda =", lam)
  )
}))
df_lambda$lambda <- factor(df_lambda$lambda, levels = paste("lambda =", lambdas))

ggplot(df_lambda, aes(x = t, y = value, color = type, linewidth = type)) +
  geom_line() +
  scale_color_manual(values = c("Original" = "gray50", "Smoothed" = "blue")) +
  scale_linewidth_manual(values = c("Original" = 0.5, "Smoothed" = 1)) +
  facet_wrap(~ lambda, ncol = 2) +
  labs(x = "t", y = "X(t)", title = "P-spline Smoothing with Different Lambda") +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank())
```

### Automatic Lambda Selection

P-splines can automatically select the optimal smoothing parameter:

```{r pspline-auto}
# Automatic lambda selection using GCV
result_auto <- pspline(fd[1], nbasis = 25, lambda.select = TRUE, criterion = "GCV")
cat("Selected lambda:", result_auto$lambda, "\n")
cat("Effective df:", round(result_auto$edf, 2), "\n")

# Plot result
df_auto <- data.frame(
  t = rep(t, 3),
  value = c(fd$data[1, ], result_auto$fdata$data[1, ], true_signal(t)),
  type = factor(c(rep("Observed", length(t)),
                  rep("P-spline", length(t)),
                  rep("True signal", length(t))),
                levels = c("Observed", "P-spline", "True signal"))
)

ggplot(df_auto, aes(x = t, y = value, color = type, linetype = type, linewidth = type)) +
  geom_line() +
  scale_color_manual(values = c("Observed" = "gray50", "P-spline" = "blue",
                                 "True signal" = "red")) +
  scale_linetype_manual(values = c("Observed" = "solid", "P-spline" = "solid",
                                    "True signal" = "dashed")) +
  scale_linewidth_manual(values = c("Observed" = 0.5, "P-spline" = 1, "True signal" = 1)) +
  labs(x = "t", y = "X(t)", title = "P-spline with Auto-selected Lambda") +
  theme_minimal() +
  theme(legend.position = "bottom", legend.title = element_blank())
```

### Smoothing Multiple Curves

P-splines work curve-by-curve, so you can smooth entire datasets:

```{r pspline-multiple}
# Smooth all curves with automatic lambda selection
result_all <- pspline(fd, nbasis = 25, lambda.select = TRUE)

# Plot smoothed data
plot(result_all$fdata, alpha = 0.5, main = "All curves smoothed with P-splines")
```

## Comparing Approaches

Let's compare the different smoothing approaches:

```{r comparison}
# Original noisy data
fd_single <- fd[1]

# 1. Simple basis projection (Fourier)
coefs <- fdata2basis(fd_single, nbasis = 9, type = "fourier")
fd_fourier <- basis2fdata(coefs, argvals = t, type = "fourier")

# 2. Optimal basis via CV
cv_opt <- fdata2basis.cv(fd_single, nbasis.range = 5:20, type = "fourier")
fd_cv <- cv_opt$fitted

# 3. P-spline with automatic lambda
ps_result <- pspline(fd_single, nbasis = 25, lambda.select = TRUE)
fd_pspline <- ps_result$fdata

# Plot comparison
df_comp <- data.frame(
  t = rep(t, 5),
  value = c(fd_single$data[1, ], fd_fourier$data[1, ], fd_cv$data[1, ],
            fd_pspline$data[1, ], true_signal(t)),
  method = factor(c(rep("Observed", length(t)),
                    rep("Fourier (K=9)", length(t)),
                    rep(paste0("CV-optimal (K=", cv_opt$optimal.nbasis, ")"), length(t)),
                    rep("P-spline", length(t)),
                    rep("True signal", length(t))),
                  levels = c("Observed", "Fourier (K=9)",
                             paste0("CV-optimal (K=", cv_opt$optimal.nbasis, ")"),
                             "P-spline", "True signal"))
)

ggplot(df_comp, aes(x = t, y = value, color = method, linetype = method, linewidth = method)) +
  geom_line() +
  scale_color_manual(values = c("Observed" = "gray50", "Fourier (K=9)" = "blue",
                                 "CV-optimal (K=9)" = "green", "P-spline" = "purple",
                                 "True signal" = "red",
                                 setNames("green", paste0("CV-optimal (K=", cv_opt$optimal.nbasis, ")")))) +
  scale_linetype_manual(values = c("Observed" = "solid", "Fourier (K=9)" = "solid",
                                    "CV-optimal (K=9)" = "solid", "P-spline" = "solid",
                                    "True signal" = "dashed",
                                    setNames("solid", paste0("CV-optimal (K=", cv_opt$optimal.nbasis, ")")))) +
  scale_linewidth_manual(values = c("Observed" = 0.5, "Fourier (K=9)" = 1,
                                     "CV-optimal (K=9)" = 1, "P-spline" = 1,
                                     "True signal" = 1,
                                     setNames(1, paste0("CV-optimal (K=", cv_opt$optimal.nbasis, ")")))) +
  labs(x = "t", y = "X(t)", title = "Comparison of Smoothing Methods", color = NULL) +
  theme_minimal() +
  theme(legend.position = "bottom") +
  guides(linetype = "none", linewidth = "none")
```

## Recommendations

| Situation | Recommended Approach |
|-----------|---------------------|
| Periodic data | Fourier basis with GCV selection |
| Non-periodic data | B-spline basis with GCV selection |
| Heavy noise | P-splines with automatic lambda |
| Fast processing needed | Simple basis with fixed K |
| Publication-quality | K-fold CV for robust selection |

## Summary

1. **Choose basis type** based on data characteristics:
   - Fourier for periodic patterns
   - B-splines for non-periodic data

2. **Select complexity** using information criteria:
   - `fdata2basis.cv()` for automatic nbasis selection
   - `basis.gcv()`, `basis.aic()`, `basis.bic()` for manual comparison

3. **Consider P-splines** for:
   - Heavy noise scenarios
   - When you want smooth derivatives
   - Automatic smoothing parameter selection

4. **Validate** by comparing reconstructed curves to the original data

## References

- Ramsay, J.O. and Silverman, B.W. (2005). *Functional Data Analysis*. Springer.
- Eilers, P.H.C. and Marx, B.D. (1996). Flexible smoothing with B-splines and
  penalties. *Statistical Science*, 11(2), 89-121.
